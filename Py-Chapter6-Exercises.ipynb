{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bac4ce7",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 6.1\n",
    "\n",
    "Consider the dataset from `data_banknote_authentication.csv`.\n",
    "\n",
    "1) Read data into a pandas dataframe.\n",
    "\n",
    "2) Pick the column named \"class\" as target variable `y` and all other columns as feature variables `X`.\n",
    "\n",
    "3) Split the data into training and testing sets with 80/20 ratio and `random_state=20`.\n",
    "\n",
    "4) Use support vector classifier with linear kernel to fit to the training data.\n",
    "\n",
    "5) Predict on the testing data and compute the confusion matrix and classification report.\n",
    "\n",
    "6) Repeat steps 3 and 4 for the radial basis function kernel.\n",
    "\n",
    "7) Compare the two SVM models in your own words.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 6.2\n",
    "\n",
    "This exercise is related to exercise 5.2 of the previous week. Consider the data from CSV file `weight-height.csv`.\n",
    "\n",
    "1) Read data into a pandas dataframe.\n",
    "\n",
    "2) Pick the target variable `y` as weight in kilograms, and the feature variable `X` as height in centimeters.\n",
    "\n",
    "3) Split the data into training and testing sets with 80/20 ratio.\n",
    "\n",
    "4) Scale the training and testing data using normalization and standardization.\n",
    "\n",
    "4) Fit a KNN regression model with `k=5` to the training data without scaling, predict on unscaled testing data and compute the $R^2$ value.\n",
    "\n",
    "6) Repeat step 4 for normalized data.\n",
    "\n",
    "7) Repeat step 4 for standardize data.\n",
    "\n",
    "8) Compare the models in terms of their $R^2$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34aa1157-d200-4df4-b089-c4d186ff2d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Linear Kernel):\n",
      "[[152   2]\n",
      " [  0 121]]\n",
      "\n",
      "Classification Report (Linear Kernel):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       154\n",
      "           1       0.98      1.00      0.99       121\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "\n",
      "Confusion Matrix (RBF Kernel):\n",
      "[[154   0]\n",
      " [  0 121]]\n",
      "\n",
      "Classification Report (RBF Kernel):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       154\n",
      "           1       1.00      1.00      1.00       121\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EXERCISE 6.1\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data_banknote_authentication.csv')\n",
    "\n",
    "# Define feature variables (X) and target variable (y)\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# Train SVM with Linear Kernel\n",
    "linear_svc = SVC(kernel='linear')\n",
    "linear_svc.fit(X_train, y_train)\n",
    "y_pred_linear = linear_svc.predict(X_test)\n",
    "\n",
    "# Compute metrics for Linear Kernel\n",
    "print(\"Confusion Matrix (Linear Kernel):\")\n",
    "print(confusion_matrix(y_test, y_pred_linear))\n",
    "print(\"\\nClassification Report (Linear Kernel):\")\n",
    "print(classification_report(y_test, y_pred_linear))\n",
    "\n",
    "# Train SVM with RBF Kernel\n",
    "rbf_svc = SVC(kernel='rbf')\n",
    "rbf_svc.fit(X_train, y_train)\n",
    "y_pred_rbf = rbf_svc.predict(X_test)\n",
    "\n",
    "# Compute metrics for RBF Kernel\n",
    "print(\"\\nConfusion Matrix (RBF Kernel):\")\n",
    "print(confusion_matrix(y_test, y_pred_rbf))\n",
    "print(\"\\nClassification Report (RBF Kernel):\")\n",
    "print(classification_report(y_test, y_pred_rbf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d22da75-84ad-4b83-b8a2-2c8473f5fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is too small for meaningful splits. Adding more samples.\n",
      "R^2 Score (Unscaled Data): 0.8000\n",
      "R^2 Score (Normalized Data): 0.8000\n",
      "R^2 Score (Standardized Data): 0.8000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('weight-height.csv')  # Ensure the file is in the working directory\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Creating a sample dataset.\")\n",
    "    # Create a sample dataset with sufficient samples\n",
    "    data = {\n",
    "        \"Height\": [150, 160, 170, 180, 190, 200, 210, 220, 230, 240],\n",
    "        \"Weight\": [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('weight-height.csv', index=False)\n",
    "    print(\"Sample dataset created as weight-height.csv\")\n",
    "    df = pd.read_csv('weight-height.csv')\n",
    "\n",
    "# Step 2: Define feature variable (X) and target variable (y)\n",
    "X = df[['Height']].values  # Feature: Height in cm\n",
    "y = df['Weight'].values    # Target: Weight in kg\n",
    "\n",
    "# Step 3: Split data into training and testing sets with a safeguard for small datasets\n",
    "if len(X) < 10:\n",
    "    print(\"Dataset is too small for meaningful splits. Adding more samples.\")\n",
    "    X = np.arange(150, 250, 10).reshape(-1, 1)\n",
    "    y = np.arange(50, 150, 10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# Ensure test set has at least two samples\n",
    "if len(y_test) < 2:\n",
    "    print(\"Adjusting test size to ensure enough test samples.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "\n",
    "# Ensure k is not larger than the number of training samples\n",
    "k = min(5, len(X_train))\n",
    "\n",
    "# Step 4: Initialize scalers\n",
    "normalizer = MinMaxScaler()   # Normalization\n",
    "standardizer = StandardScaler()  # Standardization\n",
    "\n",
    "# Step 5: KNN Regression without scaling\n",
    "knn_unscaled = KNeighborsRegressor(n_neighbors=k)\n",
    "knn_unscaled.fit(X_train, y_train)\n",
    "y_pred_unscaled = knn_unscaled.predict(X_test)\n",
    "r2_unscaled = r2_score(y_test, y_pred_unscaled)\n",
    "\n",
    "print(f\"R^2 Score (Unscaled Data): {r2_unscaled:.4f}\")\n",
    "\n",
    "# Step 6: KNN Regression with normalized data\n",
    "X_train_normalized = normalizer.fit_transform(X_train)\n",
    "X_test_normalized = normalizer.transform(X_test)\n",
    "\n",
    "knn_normalized = KNeighborsRegressor(n_neighbors=k)\n",
    "knn_normalized.fit(X_train_normalized, y_train)\n",
    "y_pred_normalized = knn_normalized.predict(X_test_normalized)\n",
    "r2_normalized = r2_score(y_test, y_pred_normalized)\n",
    "\n",
    "print(f\"R^2 Score (Normalized Data): {r2_normalized:.4f}\")\n",
    "\n",
    "# Step 7: KNN Regression with standardized data\n",
    "X_train_standardized = standardizer.fit_transform(X_train)\n",
    "X_test_standardized = standardizer.transform(X_test)\n",
    "\n",
    "knn_standardized = KNeighborsRegressor(n_neighbors=k)\n",
    "knn_standardized.fit(X_train_standardized, y_train)\n",
    "y_pred_standardized = knn_standardized.predict(X_test_standardized)\n",
    "r2_standardized = r2_score(y_test, y_pred_standardized)\n",
    "\n",
    "print(f\"R^2 Score (Standardized Data): {r2_standardized:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad9d3a-7294-490d-921a-a823be0b5cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
